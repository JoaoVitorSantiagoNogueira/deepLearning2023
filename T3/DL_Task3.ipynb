{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "v91AKKi6rG4j"
      ],
      "authorship_tag": "ABX9TyNqfObFMozYodJrUoZ3oWaU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoaoVitorSantiagoNogueira/deepLearning2023/blob/main/T3/DL_Task3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3\n",
        "\n",
        "Test different auto-encoder architectures"
      ],
      "metadata": {
        "id": "6RDf_TdnqIvO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Theory"
      ],
      "metadata": {
        "id": "v91AKKi6rG4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### references:"
      ],
      "metadata": {
        "id": "vSJgQFsUq3GC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1]\n",
        "[2]\n",
        "..."
      ],
      "metadata": {
        "id": "grScMvohq8c9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code"
      ],
      "metadata": {
        "id": "tVGpJpY9rBUq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Intialization"
      ],
      "metadata": {
        "id": "2Kfbwn41rN9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "P8CWCb-Urdle"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model definition"
      ],
      "metadata": {
        "id": "2L4RIaC13u-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "auto encoder used on a [previous work](https://github.com/JoaoVitorSantiagoNogueira/tcc-testes), removing the middle layers as no processing needs to be done. This will serve as our baseline. Steal model concatenation from task2"
      ],
      "metadata": {
        "id": "upj7ZS6J4Kds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class BaseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaseNetwork, self).__init__()\n",
        "\n",
        "    def init_weights(self, init_type='normal', gain=0.02):\n",
        "        '''\n",
        "        initialize network's weights\n",
        "        init_type: normal | xavier | kaiming | orthogonal\n",
        "        https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/9451e70673400885567d08a9e97ade2524c700d0/models/networks.py#L39\n",
        "        '''\n",
        "\n",
        "        def init_func(m):\n",
        "            classname = m.__class__.__name__\n",
        "            if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
        "                if init_type == 'normal':\n",
        "                    nn.init.normal_(m.weight.data, 0.0, gain)\n",
        "                elif init_type == 'xavier':\n",
        "                    nn.init.xavier_normal_(m.weight.data, gain=gain)\n",
        "                elif init_type == 'kaiming':\n",
        "                    nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
        "                elif init_type == 'orthogonal':\n",
        "                    nn.init.orthogonal_(m.weight.data, gain=gain)\n",
        "\n",
        "                if hasattr(m, 'bias') and m.bias is not None:\n",
        "                    nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "            elif classname.find('BatchNorm2d') != -1:\n",
        "                nn.init.normal_(m.weight.data, 1.0, gain)\n",
        "                nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "        self.apply(init_func)\n"
      ],
      "metadata": {
        "id": "6upsFwKg5u_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InpaintGenerator(BaseNetwork):\n",
        "    def __init__(self, residual_blocks=8, init_weights=True):\n",
        "        super(InpaintGenerator, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(in_channels=4, out_channels=64, kernel_size=7, padding=0),\n",
        "            nn.InstanceNorm2d(64, track_running_stats=False),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(128, track_running_stats=False),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(256, track_running_stats=False),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "\n",
        "        #blocks = []\n",
        "        #for _ in range(residual_blocks):\n",
        "        #    block = ResnetBlock(256, 2)\n",
        "        #    blocks.append(block)\n",
        "\n",
        "        #self.middle = nn.Sequential(*blocks)\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            # [batch_size, 256, 64, 64]\n",
        "            #nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=1),\n",
        "            #changes to avoid chckered patterns, parameters chosen to keep the same dimensions\n",
        "            nn.Upsample(scale_factor= 4, mode='bilinear'),\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=0),\n",
        "            # [batch_size, 128, 128, 128]\n",
        "\n",
        "\n",
        "            nn.InstanceNorm2d(128, track_running_stats=False),\n",
        "            nn.ReLU(True),\n",
        "            #nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Upsample(scale_factor= 4, mode='bilinear'),\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=4, stride=2, padding=0),\n",
        "            # [batch_size, 64, 256, 256]\n",
        "\n",
        "\n",
        "            nn.InstanceNorm2d(64, track_running_stats=False),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ReflectionPad2d(3),\n",
        "            # [batch_size, 64, 262, 262]\n",
        "            nn.Conv2d(in_channels=64, out_channels=3, kernel_size=7, padding=0),\n",
        "            # [batch_size, 3, 256, 256]\n",
        "        )\n",
        "\n",
        "        if init_weights:\n",
        "            self.init_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        #x = self.middle(x)\n",
        "        x = self.decoder(x)\n",
        "        x = (torch.tanh(x) + 1) / 2\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "awLlubzl3xv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QvJg076_3udF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training"
      ],
      "metadata": {
        "id": "r-1gbfUirQk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usage"
      ],
      "metadata": {
        "id": "bPtsmMUArUpQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization\n"
      ],
      "metadata": {
        "id": "qbYs2gierYeI"
      }
    }
  ]
}